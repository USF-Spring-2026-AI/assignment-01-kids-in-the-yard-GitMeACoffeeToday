ASSIGNMENT 1 | REFLECTION ANSWERS


Awad distinguishes between different “types” of AI. What classification scheme does the paper
use and why do these types matter for scientific research?

- Awad classifies different types of AI by their use cases in their relevant
  fields, for example, distinguishing between Predictive AI in biomedicine and
Predictive AI in something else like Climate Modelling. Different use cases can
have radically different requirements and contexts such that there is no uniform
"one size fits all" AI type, but rather specializations that have some distant
similarities to each other.


Does Awad make a clear distinction between AI as a tool and AI as a scientific collaborator? If so,
what are the differences and what are some examples given to support the differences? Do these
examples suggest a real shift in how science is conducted, or mostly an extension of existing
methods?

-  Awad does make a distinction between the two currently. He acknowledges that
   AI has proven itself as a capable tool in scientific applications like data
analysis and pattern discovery, accelerating research. However, Awad also states
that AI -another specialization of it- has begun to take the role of 'epistemic agents', 
in not only just processing, but also in drawing conclusions upon said information, a role that has
traditionally been reserved to humans. AI Agents can make decisions, have
adaptive behavior, and prioritize their efforts with information at hand.
Awad states that these Agents are, 'beginning to act as active collaborators in
the discovery process'. Through usage of AI agents, research teams may be two or threefold
as productive as before, augmented with a tireless and ever vigilant
accompaniment that may provide helpful insights into the data they analyze.
Science may very well be more effiently conducted than ever with AI, but it is
not likely to be completely automated. Original methods of science will remain
as is, accelerated greatly by AI, both as tools and collaborators, and humans
will remain at the forefront; reviewing and concluding.



What are some limitations or risks of using AI in science? How do these relate to issues such as
interpretability, bias, reproducibility, or theory formation?

- AI has the possibility of spreading 'authoritative-sounding' information that
  may be factually incorrect, as well as having difficulties in reproducing said
information, even if the same inputs and weights are present. Additionally, the
fact that AI can 'confidently' express incorrect information, and will continue
to do so until manually corrected. 



According to Awad’s arguments, is AI more likely to accelerate scientific discovery or to reshape
the scientific method itself? Do you agree or disagree?

- According to Awad, AI is likely to do both, and already accelerates scientific
  discovery in multiple fields. However, when it comes to affecting the
scientific method itself, Awad does raise some concerns regarding the growing
autonomy of AI in formulating hypothesis and independently reasoning without
human intervention, as he believes that there is a potential issue in
verifying the work produced and in assigning responsibility for said work. 

I personally agree with this, as while there are great benefits to be had from
incorporating Artificial Intelligence (in its many forms) in areas of
scientific research, there is a valid concern in accountability for scientific
knowledge generated by AI. How is the information interpreted? How much of it
was influenced or produced in cohort with human intervention? And most
importantly, how far is 'far'? Are there fields that may just not be suited for
AI application, yet we still try to apply it, regardless of the consequences?
